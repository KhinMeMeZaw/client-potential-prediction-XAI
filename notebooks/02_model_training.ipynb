{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02 - Model Training\n",
        "This notebook focuses on training multiple ML models (Gradient Boosting, LightGBM, Random Forest, etc.)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#  Define Features (X) and Target (y) ---\n",
        "# Drop original string columns that have been encoded and the original target\n",
        "X = df.drop(columns=['Potential Label', 'Potential Label_Encoded', 'Engagement Level', 'Urgency Level'])\n",
        "y = df['Potential Label_Encoded'].astype(int) # Ensure target is integer type for classification\n",
        "\n",
        "print(\"Shape of features (X):\", X.shape)\n",
        "print(\"Shape of target (y):\", y.shape)\n",
        "\n",
        "# --- 4. Perform Manual Cross-Validation ---\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier # Import RandomForestClassifier\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score # Import StratifiedKFold and cross_val_score\n",
        "\n",
        "# Initialize the RandomForestClassifier\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Set up Stratified K-Fold Cross-Validation\n",
        "# StratifiedKFold is crucial for classification to ensure each fold has\n",
        "# approximately the same percentage of samples of each target class.\n",
        "n_splits = 10 # Common choices are 3, 5, or 10 folds\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "# Perform cross-validation\n",
        "# `cross_val_score` trains and evaluates the model on each fold\n",
        "accuracy_scores = cross_val_score(rf_model, X, y, cv=skf, scoring='accuracy')\n",
        "\n",
        "print(f\"\\n--- Cross-Validation Results ({n_splits}-Fold) ---\")\n",
        "print(f\"Accuracy scores for each of the {n_splits} folds:\")\n",
        "for i, score in enumerate(accuracy_scores):\n",
        "    print(f\"Fold {i+1}: {score:.4f}\")\n",
        "\n",
        "print(f\"\\nMean accuracy across {n_splits} folds: {accuracy_scores.mean():.4f}\")\n",
        "print(f\"Standard deviation of accuracy across {n_splits} folds: {accuracy_scores.std():.4f}\")\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression # Corrected import\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# --- 3. Define Features (X) and Target (y) ---\n",
        "# Drop original string columns that have been encoded and the original target\n",
        "X = df.drop(columns=['Potential Label', 'Potential Label_Encoded', 'Engagement Level', 'Urgency Level'])\n",
        "y = df['Potential Label_Encoded'].astype(int) # Ensure target is integer type for classification\n",
        "\n",
        "print(\"Shape of features (X):\", X.shape)\n",
        "print(\"Shape of target (y):\", y.shape)\n",
        "\n",
        "# --- 4. Set up Stratified K-Fold Cross-Validation ---\n",
        "n_splits = 10\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "print(f\"\\n--- Cross-Validation Results ({n_splits}-Fold) for Different Algorithms ---\")\n",
        "\n",
        "# --- Logistic Regression ---\n",
        "print(\"\\n--- Logistic Regression ---\")\n",
        "log_reg_model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "accuracy_scores_lr = cross_val_score(log_reg_model, X, y, cv=skf, scoring='accuracy')\n",
        "print(f\"Accuracy scores for each of the {n_splits} folds:\")\n",
        "for i, score in enumerate(accuracy_scores_lr):\n",
        "    print(f\"Fold {i+1}: {score:.4f}\")\n",
        "print(f\"Mean Accuracy: {accuracy_scores_lr.mean():.4f}\")\n",
        "print(f\"Std Dev Accuracy: {accuracy_scores_lr.std():.4f}\")\n",
        "\n",
        "# --- Support Vector Classifier (SVC) ---\n",
        "print(\"\\n--- Support Vector Classifier (SVC) ---\")\n",
        "svc_model = SVC(random_state=42)\n",
        "accuracy_scores_svc = cross_val_score(svc_model, X, y, cv=skf, scoring='accuracy')\n",
        "print(f\"Accuracy scores for each of the {n_splits} folds:\")\n",
        "for i, score in enumerate(accuracy_scores_svc):\n",
        "    print(f\"Fold {i+1}: {score:.4f}\")\n",
        "print(f\"Mean Accuracy: {accuracy_scores_svc.mean():.4f}\")\n",
        "print(f\"Std Dev Accuracy: {accuracy_scores_svc.std():.4f}\")\n",
        "\n",
        "# --- K-Nearest Neighbors Classifier ---\n",
        "print(\"\\n--- K-Nearest Neighbors Classifier ---\")\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5) # Default n_neighbors, can be tuned\n",
        "accuracy_scores_knn = cross_val_score(knn_model, X, y, cv=skf, scoring='accuracy')\n",
        "print(f\"Accuracy scores for each of the {n_splits} folds:\")\n",
        "for i, score in enumerate(accuracy_scores_knn):\n",
        "    print(f\"Fold {i+1}: {score:.4f}\")\n",
        "print(f\"Mean Accuracy: {accuracy_scores_knn.mean():.4f}\")\n",
        "print(f\"Std Dev Accuracy: {accuracy_scores_knn.std():.4f}\")\n",
        "\n",
        "# --- Decision Tree Classifier ---\n",
        "print(\"\\n--- Decision Tree Classifier ---\")\n",
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "accuracy_scores_dt = cross_val_score(dt_model, X, y, cv=skf, scoring='accuracy')\n",
        "print(f\"Accuracy scores for each of the {n_splits} folds:\")\n",
        "for i, score in enumerate(accuracy_scores_dt):\n",
        "    print(f\"Fold {i+1}: {score:.4f}\")\n",
        "print(f\"Mean Accuracy: {accuracy_scores_dt.mean():.4f}\")\n",
        "print(f\"Std Dev Accuracy: {accuracy_scores_dt.std():.4f}\")\n",
        "\n",
        "# --- Gaussian Naive Bayes ---\n",
        "print(\"\\n--- Gaussian Naive Bayes ---\")\n",
        "gnb_model = GaussianNB()\n",
        "accuracy_scores_gnb = cross_val_score(gnb_model, X, y, cv=skf, scoring='accuracy')\n",
        "print(f\"Accuracy scores for each of the {n_splits} folds:\")\n",
        "for i, score in enumerate(accuracy_scores_gnb):\n",
        "    print(f\"Fold {i+1}: {score:.4f}\")\n",
        "print(f\"Mean Accuracy: {accuracy_scores_gnb.mean():.4f}\")\n",
        "print(f\"Std Dev Accuracy: {accuracy_scores_gnb.std():.4f}\")\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 4: Save models\n",
        "# joblib.dump(model, '../models/gradient_boosting_model.pkl')"
      ]
    }
  ],
  "metadata": {
    "language": "python",
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
