{
 "cells": [
  {"cell_type": "markdown", "metadata": {}, "source": ["# 03 - Model Evaluation\n", "This notebook evaluates model performance using accuracy, precision, recall, F1-score, and confusion matrix."]},
  {"cell_type": "code", "metadata": {}, "source": ["# Step 1: Import evaluation metrics\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"]},
  {"cell_type": "code", "metadata": {}, "source": ["# Step 2: Evaluate model predictions\n# y_pred = model.predict(X_test)\n# print('Accuracy:', accuracy_score(y_test, y_pred))"]},
  {"cell_type": "code", "metadata": {}, "source": ["# Step 3: Plot confusion matrix or classification report\n# import matplotlib.pyplot as plt\n# from sklearn.metrics import ConfusionMatrixDisplay\n# ConfusionMatrixDisplay.from_estimator(model, X_test, y_test)\n# plt.show()"]}
 ],
 "metadata": {"language": "python"},
 "nbformat": 4,
 "nbformat_minor": 5
}